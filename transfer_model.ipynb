{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xs2445/envs/ffb6dEnv/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import (\n",
    "    division,\n",
    "    absolute_import,\n",
    "    with_statement,\n",
    "    print_function,\n",
    "    unicode_literals,\n",
    ")\n",
    "import os\n",
    "import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from common import Config, ConfigRandLA\n",
    "from models.ffb6d import FFB6D\n",
    "from datasets.ycb.ycb_dataset import Dataset as YCB_Dataset\n",
    "from datasets.linemod.linemod_dataset import Dataset as LM_Dataset\n",
    "from utils.pvn3d_eval_utils_kpls import cal_frame_poses, cal_frame_poses_lm\n",
    "from utils.basic_utils import Basic_Utils\n",
    "try:\n",
    "    from neupeak.utils.webcv2 import imshow, waitKey\n",
    "except ImportError:\n",
    "    from cv2 import imshow, waitKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AXIS_PTS = np.array([[0,0,0],\n",
    "                     [0.1,0,0],\n",
    "                     [0,0.1,0],\n",
    "                     [0,0,0.1]])\n",
    "\n",
    "COLORS = [[250,0,0],\n",
    "          [0,250,0],\n",
    "          [0,0,250]]\n",
    "\n",
    "def ensure_fd(fd):\n",
    "    if not os.path.exists(fd):\n",
    "        os.system('mkdir -p {}'.format(fd))\n",
    "\n",
    "def load_checkpoint(model=None, optimizer=None, filename=\"checkpoint\"):\n",
    "    filename = \"{}.pth.tar\".format(filename)\n",
    "\n",
    "    assert os.path.isfile(filename), \"==> Checkpoint '{}' not found\".format(filename)\n",
    "    print(\"==> Loading from checkpoint '{}'\".format(filename))\n",
    "    try:\n",
    "        checkpoint = torch.load(filename)\n",
    "    except Exception:\n",
    "        checkpoint = pkl.load(open(filename, \"rb\"))\n",
    "    epoch = checkpoint.get(\"epoch\", 0)\n",
    "    it = checkpoint.get(\"it\", 0.0)\n",
    "    best_prec = checkpoint.get(\"best_prec\", None)\n",
    "    if model is not None and checkpoint[\"model_state\"] is not None:\n",
    "        ck_st = checkpoint['model_state']\n",
    "        if 'module' in list(ck_st.keys())[0]:\n",
    "            tmp_ck_st = {}\n",
    "            for k, v in ck_st.items():\n",
    "                tmp_ck_st[k.replace(\"module.\", \"\")] = v\n",
    "            ck_st = tmp_ck_st\n",
    "        model.load_state_dict(ck_st)\n",
    "    if optimizer is not None and checkpoint[\"optimizer_state\"] is not None:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    print(\"==> Done\")\n",
    "    return it, epoch, best_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(ds_name='linemod', cls_type='ape')\n",
    "\n",
    "bs_utils = Basic_Utils(config)\n",
    "\n",
    "checkpoint_path='/home/xs2445/6895/FFB6D/ffb6d/train_log/linemod/checkpoints/ape/FFB6D_ape_best.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading resnet34 pretrained mdl.\n",
      "==> Loading from checkpoint '/home/xs2445/6895/FFB6D/ffb6d/train_log/linemod/checkpoints/ape/FFB6D_ape_best.pth.tar'\n",
      "==> Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndla_cfg = ConfigRandLA\n",
    "model = FFB6D(\n",
    "    n_classes=config.n_objects, n_pts=config.n_sample_points, rndla_cfg=rndla_cfg,\n",
    "    n_kps=config.n_keypoints\n",
    ")\n",
    "# model.cuda()\n",
    "load_checkpoint(\n",
    "    model, None, filename=checkpoint_path[:-8]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFB6D(\n",
      "  (cnn_pre_stages): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (rndla_pre_stages): Conv1d(\n",
      "    (conv): Conv1d(9, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (bn): BatchNorm1d(\n",
      "      (bn): BatchNorm1d(8, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (cnn_ds_stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (3): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (4): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (5): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): PSPModule(\n",
      "        (stages): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=(2, 2))\n",
      "            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): Conv2d(2560, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): Dropout2d(p=0.3, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (rndla_ds_stages): ModuleList(\n",
      "    (0): Dilated_res_block(\n",
      "      (mlp1): Conv2d(\n",
      "        (conv): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(16, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (lfa): Building_block(\n",
      "        (mlp1): Conv2d(\n",
      "          (conv): Conv2d(10, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(\n",
      "            (bn): BatchNorm2d(16, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (att_pooling_1): Att_pooling(\n",
      "          (fc): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (mlp): Conv2d(\n",
      "            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(\n",
      "              (bn): BatchNorm2d(16, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (mlp2): Conv2d(\n",
      "          (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(\n",
      "            (bn): BatchNorm2d(16, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (att_pooling_2): Att_pooling(\n",
      "          (fc): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (mlp): Conv2d(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(\n",
      "              (bn): BatchNorm2d(32, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp2): Conv2d(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(64, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Conv2d(\n",
      "        (conv): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(64, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Dilated_res_block(\n",
      "      (mlp1): Conv2d(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(32, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (lfa): Building_block(\n",
      "        (mlp1): Conv2d(\n",
      "          (conv): Conv2d(10, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(\n",
      "            (bn): BatchNorm2d(32, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (att_pooling_1): Att_pooling(\n",
      "          (fc): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (mlp): Conv2d(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(\n",
      "              (bn): BatchNorm2d(32, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (mlp2): Conv2d(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(\n",
      "            (bn): BatchNorm2d(32, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (att_pooling_2): Att_pooling(\n",
      "          (fc): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (mlp): Conv2d(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(\n",
      "              (bn): BatchNorm2d(64, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp2): Conv2d(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(128, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Conv2d(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(128, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Dilated_res_block(\n",
      "      (mlp1): Conv2d(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(64, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (lfa): Building_block(\n",
      "        (mlp1): Conv2d(\n",
      "          (conv): Conv2d(10, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(\n",
      "            (bn): BatchNorm2d(64, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (att_pooling_1): Att_pooling(\n",
      "          (fc): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (mlp): Conv2d(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(\n",
      "              (bn): BatchNorm2d(64, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (mlp2): Conv2d(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(\n",
      "            (bn): BatchNorm2d(64, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (att_pooling_2): Att_pooling(\n",
      "          (fc): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (mlp): Conv2d(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(\n",
      "              (bn): BatchNorm2d(128, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp2): Conv2d(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(256, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Conv2d(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(256, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Dilated_res_block(\n",
      "      (mlp1): Conv2d(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(128, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (lfa): Building_block(\n",
      "        (mlp1): Conv2d(\n",
      "          (conv): Conv2d(10, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(\n",
      "            (bn): BatchNorm2d(128, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (att_pooling_1): Att_pooling(\n",
      "          (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (mlp): Conv2d(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(\n",
      "              (bn): BatchNorm2d(128, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (mlp2): Conv2d(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(\n",
      "            (bn): BatchNorm2d(128, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (att_pooling_2): Att_pooling(\n",
      "          (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (mlp): Conv2d(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(\n",
      "              (bn): BatchNorm2d(256, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp2): Conv2d(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(512, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Conv2d(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(\n",
      "          (bn): BatchNorm2d(512, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ds_fuse_r2p_pre_layers): ModuleList(\n",
      "    (0): Conv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Conv2d(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (ds_fuse_r2p_fuse_layers): ModuleList(\n",
      "    (0): Conv2d(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Conv2d(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (ds_fuse_p2r_pre_layers): ModuleList(\n",
      "    (0): Conv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Conv2d(\n",
      "      (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (ds_fuse_p2r_fuse_layers): ModuleList(\n",
      "    (0): Conv2d(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Conv2d(\n",
      "      (conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (cnn_up_stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): PSPUpsample(\n",
      "        (conv): Sequential(\n",
      "          (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "          (1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): PReLU(num_parameters=1)\n",
      "        )\n",
      "      )\n",
      "      (1): Dropout2d(p=0.15, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): PSPUpsample(\n",
      "        (conv): Sequential(\n",
      "          (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "          (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): PReLU(num_parameters=1)\n",
      "        )\n",
      "      )\n",
      "      (1): Dropout2d(p=0.15, inplace=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LogSoftmax(dim=None)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): PSPUpsample(\n",
      "        (conv): Sequential(\n",
      "          (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): PReLU(num_parameters=1)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LogSoftmax(dim=None)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (rndla_up_stages): ModuleList(\n",
      "    (0): Conv2d(\n",
      "      (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(\n",
      "      (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (3): Conv2d(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-06, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (up_fuse_r2p_pre_layers): ModuleList(\n",
      "    (0): Conv2d(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (up_fuse_r2p_fuse_layers): ModuleList(\n",
      "    (0): Conv2d(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (up_fuse_p2r_pre_layers): ModuleList(\n",
      "    (0): Conv2d(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (up_fuse_p2r_fuse_layers): ModuleList(\n",
      "    (0): Conv2d(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Conv2d(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normlayer): BatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (rgbd_seg_layer): Seq(\n",
      "    (0): Conv1d(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (normlayer): BatchNorm1d(\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv1d(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (normlayer): BatchNorm1d(\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv1d(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (normlayer): BatchNorm1d(\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv1d(\n",
      "      (conv): Conv1d(128, 2, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (ctr_ofst_layer): Seq(\n",
      "    (0): Conv1d(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (normlayer): BatchNorm1d(\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv1d(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (normlayer): BatchNorm1d(\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv1d(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (normlayer): BatchNorm1d(\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv1d(\n",
      "      (conv): Conv1d(128, 3, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (kp_ofst_layer): Seq(\n",
      "    (0): Conv1d(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (normlayer): BatchNorm1d(\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): Conv1d(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (normlayer): BatchNorm1d(\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): Conv1d(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (normlayer): BatchNorm1d(\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (3): Conv1d(\n",
      "      (conv): Conv1d(128, 24, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_id in lm_dataset.py 1\n",
      "test_dataset_size:  1050\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "test_ds = LM_Dataset('test', cls_type='ape')\n",
    "print(config.mini_batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_ds, batch_size=1, shuffle=False,\n",
    "        num_workers=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kps_pth in get_kps: datasets/linemod/kps_orb9_fps/ape_8_kps.txt\n",
      "kps_pth in get_kps:kps_pth in get_kps:  kps_pth in get_kps:datasets/linemod/kps_orb9_fps/ape_8_kps.txtdatasets/linemod/kps_orb9_fps/ape_8_kps.txtkps_pth in get_kps: \n",
      "kps_pth in get_kps:\n",
      "datasets/linemod/kps_orb9_fps/ape_8_kps.txt\n",
      " datasets/linemod/kps_orb9_fps/ape_8_kps.txt \n",
      "datasets/linemod/kps_orb9_fps/ape_8_kps.txtkps_pth in get_kps:kps_pth in get_kps:\n",
      "kps_pth in get_kps:kps_pth in get_kps:  kps_pth in get_kps:datasets/linemod/kps_orb9_fps/ape_8_kps.txt   \n",
      "datasets/linemod/kps_orb9_fps/ape_8_kps.txtdatasets/linemod/kps_orb9_fps/ape_8_kps.txtkps_pth in get_kps:datasets/linemod/kps_orb9_fps/ape_8_kps.txt\n",
      "\n",
      "datasets/linemod/kps_orb9_fps/ape_8_kps.txtkps_pth in get_kps:kps_pth in get_kps: \n",
      "\n",
      " datasets/linemod/kps_orb9_fps/ape_8_kps.txt datasets/linemod/kps_orb9_fps/ape_8_kps.txt\n",
      "kps_pth in get_kps:kps_pth in get_kps:datasets/linemod/kps_orb9_fps/ape_8_kps.txt\n",
      "\n",
      "  kps_pth in get_kps:kps_pth in get_kps:datasets/linemod/kps_orb9_fps/ape_8_kps.txtdatasets/linemod/kps_orb9_fps/ape_8_kps.txtkps_pth in get_kps: \n",
      " kps_pth in get_kps:datasets/linemod/kps_orb9_fps/ape_8_kps.txt datasets/linemod/kps_orb9_fps/ape_8_kps.txt\n",
      "\n",
      " \n",
      "datasets/linemod/kps_orb9_fps/ape_8_kps.txtdatasets/linemod/kps_orb9_fps/ape_8_kps.txt\n",
      "\n",
      "{'rgb': tensor([[[[ 33,  35,  37,  ..., 172, 172, 171],\n",
      "          [ 31,  32,  34,  ..., 172, 172, 171],\n",
      "          [ 32,  32,  31,  ..., 173, 170, 170],\n",
      "          ...,\n",
      "          [ 36,  38,  40,  ...,  79,  79,  83],\n",
      "          [ 36,  37,  39,  ...,  79,  77,  81],\n",
      "          [ 37,  38,  39,  ...,  80,  79,  80]],\n",
      "\n",
      "         [[ 37,  39,  40,  ..., 175, 175, 174],\n",
      "          [ 35,  36,  37,  ..., 175, 175, 174],\n",
      "          [ 35,  35,  34,  ..., 176, 176, 176],\n",
      "          ...,\n",
      "          [ 42,  44,  48,  ...,  71,  70,  74],\n",
      "          [ 44,  45,  47,  ...,  71,  69,  73],\n",
      "          [ 45,  46,  47,  ...,  73,  71,  72]],\n",
      "\n",
      "         [[ 48,  50,  49,  ..., 192, 192, 191],\n",
      "          [ 46,  45,  46,  ..., 192, 192, 191],\n",
      "          [ 44,  42,  41,  ..., 193, 192, 192],\n",
      "          ...,\n",
      "          [ 56,  58,  61,  ...,  60,  61,  65],\n",
      "          [ 55,  56,  58,  ...,  58,  58,  62],\n",
      "          [ 56,  57,  58,  ...,  57,  58,  59]]]], dtype=torch.uint8), 'cld_rgb_nrm': tensor([[[ 0.3121,  0.0691, -0.2558,  ..., -0.2304,  0.3109, -0.0258],\n",
      "         [-0.2707,  0.4712, -0.1584,  ...,  0.2925, -0.3048, -0.3840],\n",
      "         [ 1.1850,  1.5360,  1.0440,  ...,  0.7080,  1.1730,  1.4390],\n",
      "         ...,\n",
      "         [-0.3761,  0.0000,  0.0000,  ...,  0.0000, -0.2402,  0.4791],\n",
      "         [ 0.5856, -0.7004, -0.8705,  ...,  0.0000,  0.2480, -0.5827],\n",
      "         [-0.7561, -0.7078, -0.4145,  ...,  0.0000, -0.9348, -0.6543]]]), 'choose': tensor([[[ 71516, 267871,  99385,  ..., 306699,  59997,  57275]]],\n",
      "       dtype=torch.int32), 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32), 'rgb_labels': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32), 'dpt_map_m': tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.6380, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.6380, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.6380, 0.0000, 0.0000]]]), 'RTs': tensor([[[[ 0.0963,  0.9940,  0.0510, -0.1054],\n",
      "          [ 0.5733, -0.0135, -0.8192, -0.1175],\n",
      "          [-0.8137,  0.1081, -0.5712,  1.0149]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]]]), 'kp_targ_ofst': tensor([[[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]]), 'ctr_targ_ofst': tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]]), 'cls_ids': tensor([[[1],\n",
      "         [0]]], dtype=torch.int32), 'ctr_3ds': tensor([[[-0.1069, -0.1274,  1.0101],\n",
      "         [ 0.0000,  0.0000,  0.0000]]]), 'kp_3ds': tensor([[[[-0.1414, -0.0905,  1.0057],\n",
      "          [-0.0945, -0.1568,  0.9948],\n",
      "          [-0.0698, -0.0947,  1.0327],\n",
      "          [-0.1195, -0.1249,  1.0526],\n",
      "          [-0.1011, -0.0709,  1.0113],\n",
      "          [-0.1102, -0.1175,  0.9916],\n",
      "          [-0.0985, -0.0941,  1.0596],\n",
      "          [-0.1364, -0.0880,  1.0419]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]]]), 'cld_xyz0': tensor([[[ 0.3121, -0.2707,  1.1850],\n",
      "         [ 0.0691,  0.4712,  1.5360],\n",
      "         [-0.2558, -0.1584,  1.0440],\n",
      "         ...,\n",
      "         [-0.2304,  0.2925,  0.7080],\n",
      "         [ 0.3109, -0.3048,  1.1730],\n",
      "         [-0.0258, -0.3840,  1.4390]]]), 'cld_nei_idx0': tensor([[[    0,  5984,  3667,  ...,  1840,  9945, 10161],\n",
      "         [    1, 12773,  1466,  ...,  6089,    75,  7021],\n",
      "         [    2,  6372, 10612,  ...,  1715,  1751,  9360],\n",
      "         ...,\n",
      "         [12797,  6520, 12494,  ...,  3195,  1443,   658],\n",
      "         [12798, 12664,  4175,  ...,  8891,  9945,   112],\n",
      "         [12799,  1663,   365,  ...,  3368,   735,  8424]]], dtype=torch.int32), 'cld_sub_idx0': tensor([[[    0,  5984,  3667,  ...,  1840,  9945, 10161],\n",
      "         [    1, 12773,  1466,  ...,  6089,    75,  7021],\n",
      "         [    2,  6372, 10612,  ...,  1715,  1751,  9360],\n",
      "         ...,\n",
      "         [ 3197,  9141,  5287,  ...,  7011,  7943,  2660],\n",
      "         [ 3198, 12376, 12689,  ..., 11189,  8084,  8642],\n",
      "         [ 3199, 10159,  6291,  ...,  3440,  9175,  5257]]], dtype=torch.int32), 'cld_interp_idx0': tensor([[[   0],\n",
      "         [   1],\n",
      "         [   2],\n",
      "         ...,\n",
      "         [1734],\n",
      "         [1500],\n",
      "         [1663]]], dtype=torch.int32), 'r2p_ds_nei_idx0': tensor([[[ 4599,  4439,  4600,  ...,  4119,  4120,  4118],\n",
      "         [16888, 16728, 16887,  ..., 16890, 17046, 17208],\n",
      "         [ 6286,  6287,  6285,  ...,  6131,  6291,  6605],\n",
      "         ...,\n",
      "         [16391, 16390, 16392,  ..., 16553, 16229, 16712],\n",
      "         [ 2686,  2687,  2846,  ...,  2525,  2367,  3005],\n",
      "         [11090, 10930, 10931,  ..., 10928, 11249, 11093]]], dtype=torch.int32), 'p2r_ds_nei_idx0': tensor([[[1123],\n",
      "         [1123],\n",
      "         [1123],\n",
      "         ...,\n",
      "         [ 144],\n",
      "         [1519],\n",
      "         [1519]]], dtype=torch.int32), 'cld_xyz1': tensor([[[ 0.3121, -0.2707,  1.1850],\n",
      "         [ 0.0691,  0.4712,  1.5360],\n",
      "         [-0.2558, -0.1584,  1.0440],\n",
      "         ...,\n",
      "         [-0.1127,  0.4525,  1.5640],\n",
      "         [ 0.3581, -0.3500,  1.1340],\n",
      "         [-0.1871,  0.0480,  0.8620]]]), 'cld_nei_idx1': tensor([[[   0,   14, 2096,  ..., 1569, 3034, 2267],\n",
      "         [   1, 1466,  916,  ..., 2687,  687, 2070],\n",
      "         [   2,  891, 2321,  ..., 1055, 1842, 2198],\n",
      "         ...,\n",
      "         [3197, 1829, 1314,  ..., 2419, 1635, 1652],\n",
      "         [3198, 2648, 2898,  ...,   24, 1435, 2439],\n",
      "         [3199, 1458,  278,  ..., 2417, 3029, 2969]]], dtype=torch.int32), 'cld_sub_idx1': tensor([[[   0,   14, 2096,  ..., 1569, 3034, 2267],\n",
      "         [   1, 1466,  916,  ..., 2687,  687, 2070],\n",
      "         [   2,  891, 2321,  ..., 1055, 1842, 2198],\n",
      "         ...,\n",
      "         [ 797, 1850,  267,  ..., 2022,  953, 2076],\n",
      "         [ 798,  957, 1168,  ..., 1638, 2433, 2863],\n",
      "         [ 799,   99, 2228,  ..., 2829, 1337,  563]]], dtype=torch.int32), 'cld_interp_idx1': tensor([[[  0],\n",
      "         [  1],\n",
      "         [  2],\n",
      "         ...,\n",
      "         [661],\n",
      "         [ 24],\n",
      "         [278]]], dtype=torch.int32), 'r2p_ds_nei_idx1': tensor([[[1180, 1100, 1099,  ...,  940,  939, 1022],\n",
      "         [4204, 4284, 4203,  ..., 4125, 4286, 4206],\n",
      "         [1623, 1624, 1625,  ..., 1706, 1547, 1467],\n",
      "         ...,\n",
      "         [1927, 1926, 1928,  ..., 1846, 2085, 1849],\n",
      "         [1329, 1330, 1248,  ..., 1332, 1167, 1089],\n",
      "         [ 337,  338,  339,  ...,  497,  420,  578]]], dtype=torch.int32), 'p2r_ds_nei_idx1': tensor([[[ 37],\n",
      "         [ 37],\n",
      "         [689],\n",
      "         ...,\n",
      "         [ 37],\n",
      "         [214],\n",
      "         [214]]], dtype=torch.int32), 'cld_xyz2': tensor([[[ 0.3121, -0.2707,  1.1850],\n",
      "         [ 0.0691,  0.4712,  1.5360],\n",
      "         [-0.2558, -0.1584,  1.0440],\n",
      "         ...,\n",
      "         [-0.5108, -0.0896,  1.0700],\n",
      "         [ 0.1615, -0.2786,  1.3650],\n",
      "         [-0.4671, -0.5120,  1.3980]]]), 'cld_nei_idx2': tensor([[[  0,  14, 112,  ...,  19,  71, 275],\n",
      "         [  1,  75,  87,  ..., 748, 508, 186],\n",
      "         [  2, 391, 324,  ..., 251, 512,  39],\n",
      "         ...,\n",
      "         [797, 267, 678,  ..., 429,  50, 695],\n",
      "         [798, 101, 103,  ..., 234, 574,  79],\n",
      "         [799,  99, 792,  ..., 364, 223, 736]]], dtype=torch.int32), 'cld_sub_idx2': tensor([[[  0,  14, 112,  ...,  19,  71, 275],\n",
      "         [  1,  75,  87,  ..., 748, 508, 186],\n",
      "         [  2, 391, 324,  ..., 251, 512,  39],\n",
      "         ...,\n",
      "         [197, 688,  76,  ..., 429,  68, 700],\n",
      "         [198, 771, 243,  ...,  27, 549, 705],\n",
      "         [199,  56, 100,  ..., 242, 777,   1]]], dtype=torch.int32), 'cld_interp_idx2': tensor([[[  0],\n",
      "         [  1],\n",
      "         [  2],\n",
      "         [  3],\n",
      "         [  4],\n",
      "         [  5],\n",
      "         [  6],\n",
      "         [  7],\n",
      "         [  8],\n",
      "         [  9],\n",
      "         [ 10],\n",
      "         [ 11],\n",
      "         [ 12],\n",
      "         [ 13],\n",
      "         [ 14],\n",
      "         [ 15],\n",
      "         [ 16],\n",
      "         [ 17],\n",
      "         [ 18],\n",
      "         [ 19],\n",
      "         [ 20],\n",
      "         [ 21],\n",
      "         [ 22],\n",
      "         [ 23],\n",
      "         [ 24],\n",
      "         [ 25],\n",
      "         [ 26],\n",
      "         [ 27],\n",
      "         [ 28],\n",
      "         [ 29],\n",
      "         [ 30],\n",
      "         [ 31],\n",
      "         [ 32],\n",
      "         [ 33],\n",
      "         [ 34],\n",
      "         [ 35],\n",
      "         [ 36],\n",
      "         [ 37],\n",
      "         [ 38],\n",
      "         [ 39],\n",
      "         [ 40],\n",
      "         [ 41],\n",
      "         [ 42],\n",
      "         [ 43],\n",
      "         [ 44],\n",
      "         [ 45],\n",
      "         [ 46],\n",
      "         [ 47],\n",
      "         [ 48],\n",
      "         [ 49],\n",
      "         [ 50],\n",
      "         [ 51],\n",
      "         [ 52],\n",
      "         [ 53],\n",
      "         [ 54],\n",
      "         [ 55],\n",
      "         [ 56],\n",
      "         [ 57],\n",
      "         [ 58],\n",
      "         [ 59],\n",
      "         [ 60],\n",
      "         [ 61],\n",
      "         [ 62],\n",
      "         [ 63],\n",
      "         [ 64],\n",
      "         [ 65],\n",
      "         [ 66],\n",
      "         [ 67],\n",
      "         [ 68],\n",
      "         [ 69],\n",
      "         [ 70],\n",
      "         [ 71],\n",
      "         [ 72],\n",
      "         [ 73],\n",
      "         [ 74],\n",
      "         [ 75],\n",
      "         [ 76],\n",
      "         [ 77],\n",
      "         [ 78],\n",
      "         [ 79],\n",
      "         [ 80],\n",
      "         [ 81],\n",
      "         [ 82],\n",
      "         [ 83],\n",
      "         [ 84],\n",
      "         [ 85],\n",
      "         [ 86],\n",
      "         [ 87],\n",
      "         [ 88],\n",
      "         [ 89],\n",
      "         [ 90],\n",
      "         [ 91],\n",
      "         [ 92],\n",
      "         [ 93],\n",
      "         [ 94],\n",
      "         [ 95],\n",
      "         [ 96],\n",
      "         [ 97],\n",
      "         [ 98],\n",
      "         [ 99],\n",
      "         [100],\n",
      "         [101],\n",
      "         [102],\n",
      "         [103],\n",
      "         [104],\n",
      "         [105],\n",
      "         [106],\n",
      "         [107],\n",
      "         [108],\n",
      "         [109],\n",
      "         [110],\n",
      "         [111],\n",
      "         [112],\n",
      "         [113],\n",
      "         [114],\n",
      "         [115],\n",
      "         [116],\n",
      "         [117],\n",
      "         [118],\n",
      "         [119],\n",
      "         [120],\n",
      "         [121],\n",
      "         [122],\n",
      "         [123],\n",
      "         [124],\n",
      "         [125],\n",
      "         [126],\n",
      "         [127],\n",
      "         [128],\n",
      "         [129],\n",
      "         [130],\n",
      "         [131],\n",
      "         [132],\n",
      "         [133],\n",
      "         [134],\n",
      "         [135],\n",
      "         [136],\n",
      "         [137],\n",
      "         [138],\n",
      "         [139],\n",
      "         [140],\n",
      "         [141],\n",
      "         [142],\n",
      "         [143],\n",
      "         [144],\n",
      "         [145],\n",
      "         [146],\n",
      "         [147],\n",
      "         [148],\n",
      "         [149],\n",
      "         [150],\n",
      "         [151],\n",
      "         [152],\n",
      "         [153],\n",
      "         [154],\n",
      "         [155],\n",
      "         [156],\n",
      "         [157],\n",
      "         [158],\n",
      "         [159],\n",
      "         [160],\n",
      "         [161],\n",
      "         [162],\n",
      "         [163],\n",
      "         [164],\n",
      "         [165],\n",
      "         [166],\n",
      "         [167],\n",
      "         [168],\n",
      "         [169],\n",
      "         [170],\n",
      "         [171],\n",
      "         [172],\n",
      "         [173],\n",
      "         [174],\n",
      "         [175],\n",
      "         [176],\n",
      "         [177],\n",
      "         [178],\n",
      "         [179],\n",
      "         [180],\n",
      "         [181],\n",
      "         [182],\n",
      "         [183],\n",
      "         [184],\n",
      "         [185],\n",
      "         [186],\n",
      "         [187],\n",
      "         [188],\n",
      "         [189],\n",
      "         [190],\n",
      "         [191],\n",
      "         [192],\n",
      "         [193],\n",
      "         [194],\n",
      "         [195],\n",
      "         [196],\n",
      "         [197],\n",
      "         [198],\n",
      "         [199],\n",
      "         [ 50],\n",
      "         [  4],\n",
      "         [ 82],\n",
      "         [133],\n",
      "         [ 53],\n",
      "         [ 79],\n",
      "         [125],\n",
      "         [ 83],\n",
      "         [126],\n",
      "         [180],\n",
      "         [ 47],\n",
      "         [ 39],\n",
      "         [ 17],\n",
      "         [154],\n",
      "         [144],\n",
      "         [192],\n",
      "         [ 77],\n",
      "         [ 45],\n",
      "         [ 80],\n",
      "         [  6],\n",
      "         [ 33],\n",
      "         [ 15],\n",
      "         [180],\n",
      "         [ 77],\n",
      "         [ 78],\n",
      "         [ 67],\n",
      "         [186],\n",
      "         [ 38],\n",
      "         [123],\n",
      "         [ 30],\n",
      "         [ 60],\n",
      "         [  8],\n",
      "         [ 39],\n",
      "         [ 10],\n",
      "         [190],\n",
      "         [174],\n",
      "         [176],\n",
      "         [ 34],\n",
      "         [ 80],\n",
      "         [ 54],\n",
      "         [ 89],\n",
      "         [ 61],\n",
      "         [186],\n",
      "         [198],\n",
      "         [ 50],\n",
      "         [146],\n",
      "         [  6],\n",
      "         [ 32],\n",
      "         [ 50],\n",
      "         [154],\n",
      "         [194],\n",
      "         [ 42],\n",
      "         [124],\n",
      "         [108],\n",
      "         [ 19],\n",
      "         [  8],\n",
      "         [ 98],\n",
      "         [ 45],\n",
      "         [128],\n",
      "         [ 72],\n",
      "         [178],\n",
      "         [125],\n",
      "         [106],\n",
      "         [ 67],\n",
      "         [178],\n",
      "         [ 66],\n",
      "         [ 78],\n",
      "         [ 84],\n",
      "         [138],\n",
      "         [ 24],\n",
      "         [152],\n",
      "         [ 83],\n",
      "         [119],\n",
      "         [ 35],\n",
      "         [135],\n",
      "         [ 19],\n",
      "         [  8],\n",
      "         [ 45],\n",
      "         [ 97],\n",
      "         [ 52],\n",
      "         [ 99],\n",
      "         [ 39],\n",
      "         [111],\n",
      "         [178],\n",
      "         [111],\n",
      "         [ 97],\n",
      "         [ 95],\n",
      "         [ 67],\n",
      "         [142],\n",
      "         [188],\n",
      "         [  3],\n",
      "         [154],\n",
      "         [190],\n",
      "         [100],\n",
      "         [ 13],\n",
      "         [ 45],\n",
      "         [ 89],\n",
      "         [ 31],\n",
      "         [108],\n",
      "         [120],\n",
      "         [108],\n",
      "         [ 55],\n",
      "         [168],\n",
      "         [  3],\n",
      "         [125],\n",
      "         [106],\n",
      "         [ 92],\n",
      "         [ 51],\n",
      "         [  6],\n",
      "         [ 57],\n",
      "         [129],\n",
      "         [ 66],\n",
      "         [ 56],\n",
      "         [131],\n",
      "         [  6],\n",
      "         [193],\n",
      "         [ 39],\n",
      "         [ 91],\n",
      "         [185],\n",
      "         [  3],\n",
      "         [ 93],\n",
      "         [165],\n",
      "         [ 50],\n",
      "         [178],\n",
      "         [ 39],\n",
      "         [119],\n",
      "         [ 89],\n",
      "         [ 94],\n",
      "         [ 13],\n",
      "         [196],\n",
      "         [ 49],\n",
      "         [164],\n",
      "         [128],\n",
      "         [ 50],\n",
      "         [166],\n",
      "         [113],\n",
      "         [ 61],\n",
      "         [188],\n",
      "         [ 41],\n",
      "         [193],\n",
      "         [166],\n",
      "         [153],\n",
      "         [ 47],\n",
      "         [109],\n",
      "         [ 54],\n",
      "         [ 46],\n",
      "         [149],\n",
      "         [167],\n",
      "         [ 57],\n",
      "         [ 17],\n",
      "         [178],\n",
      "         [ 68],\n",
      "         [ 57],\n",
      "         [ 42],\n",
      "         [ 95],\n",
      "         [ 45],\n",
      "         [153],\n",
      "         [178],\n",
      "         [176],\n",
      "         [157],\n",
      "         [186],\n",
      "         [ 72],\n",
      "         [153],\n",
      "         [156],\n",
      "         [ 86],\n",
      "         [ 45],\n",
      "         [ 48],\n",
      "         [174],\n",
      "         [ 64],\n",
      "         [ 63],\n",
      "         [ 35],\n",
      "         [ 55],\n",
      "         [167],\n",
      "         [ 57],\n",
      "         [180],\n",
      "         [178],\n",
      "         [174],\n",
      "         [ 66],\n",
      "         [ 54],\n",
      "         [188],\n",
      "         [  8],\n",
      "         [ 69],\n",
      "         [ 71],\n",
      "         [179],\n",
      "         [ 78],\n",
      "         [ 33],\n",
      "         [ 65],\n",
      "         [149],\n",
      "         [166],\n",
      "         [ 62],\n",
      "         [123],\n",
      "         [  2],\n",
      "         [166],\n",
      "         [ 80],\n",
      "         [196],\n",
      "         [ 92],\n",
      "         [178],\n",
      "         [ 39],\n",
      "         [ 71],\n",
      "         [153],\n",
      "         [ 90],\n",
      "         [ 64],\n",
      "         [  8],\n",
      "         [193],\n",
      "         [ 30],\n",
      "         [ 78],\n",
      "         [ 21],\n",
      "         [186],\n",
      "         [ 54],\n",
      "         [ 21],\n",
      "         [ 54],\n",
      "         [ 92],\n",
      "         [ 52],\n",
      "         [  4],\n",
      "         [143],\n",
      "         [129],\n",
      "         [ 82],\n",
      "         [161],\n",
      "         [100],\n",
      "         [178],\n",
      "         [182],\n",
      "         [180],\n",
      "         [176],\n",
      "         [176],\n",
      "         [ 95],\n",
      "         [ 92],\n",
      "         [153],\n",
      "         [ 59],\n",
      "         [123],\n",
      "         [ 68],\n",
      "         [ 56],\n",
      "         [132],\n",
      "         [178],\n",
      "         [150],\n",
      "         [ 19],\n",
      "         [ 23],\n",
      "         [178],\n",
      "         [ 53],\n",
      "         [ 30],\n",
      "         [ 73],\n",
      "         [ 66],\n",
      "         [111],\n",
      "         [ 36],\n",
      "         [196],\n",
      "         [ 57],\n",
      "         [ 39],\n",
      "         [172],\n",
      "         [121],\n",
      "         [108],\n",
      "         [190],\n",
      "         [ 95],\n",
      "         [121],\n",
      "         [ 57],\n",
      "         [ 57],\n",
      "         [ 82],\n",
      "         [178],\n",
      "         [ 56],\n",
      "         [ 53],\n",
      "         [132],\n",
      "         [ 83],\n",
      "         [191],\n",
      "         [ 49],\n",
      "         [ 16],\n",
      "         [186],\n",
      "         [178],\n",
      "         [ 27],\n",
      "         [195],\n",
      "         [189],\n",
      "         [ 69],\n",
      "         [ 47],\n",
      "         [ 64],\n",
      "         [ 81],\n",
      "         [125],\n",
      "         [ 16],\n",
      "         [190],\n",
      "         [  9],\n",
      "         [ 52],\n",
      "         [121],\n",
      "         [ 70],\n",
      "         [ 31],\n",
      "         [ 30],\n",
      "         [150],\n",
      "         [ 46],\n",
      "         [196],\n",
      "         [ 80],\n",
      "         [ 33],\n",
      "         [ 46],\n",
      "         [196],\n",
      "         [119],\n",
      "         [ 97],\n",
      "         [ 41],\n",
      "         [142],\n",
      "         [ 73],\n",
      "         [179],\n",
      "         [ 55],\n",
      "         [ 46],\n",
      "         [117],\n",
      "         [128],\n",
      "         [143],\n",
      "         [ 58],\n",
      "         [ 10],\n",
      "         [ 20],\n",
      "         [154],\n",
      "         [ 39],\n",
      "         [171],\n",
      "         [ 96],\n",
      "         [141],\n",
      "         [170],\n",
      "         [121],\n",
      "         [161],\n",
      "         [ 28],\n",
      "         [ 50],\n",
      "         [ 39],\n",
      "         [ 93],\n",
      "         [ 97],\n",
      "         [114],\n",
      "         [104],\n",
      "         [ 82],\n",
      "         [108],\n",
      "         [  8],\n",
      "         [  3],\n",
      "         [167],\n",
      "         [ 33],\n",
      "         [ 80],\n",
      "         [170],\n",
      "         [ 62],\n",
      "         [ 16],\n",
      "         [171],\n",
      "         [154],\n",
      "         [ 11],\n",
      "         [173],\n",
      "         [ 61],\n",
      "         [124],\n",
      "         [ 50],\n",
      "         [ 54],\n",
      "         [ 50],\n",
      "         [129],\n",
      "         [175],\n",
      "         [128],\n",
      "         [ 81],\n",
      "         [111],\n",
      "         [ 57],\n",
      "         [157],\n",
      "         [ 40],\n",
      "         [154],\n",
      "         [104],\n",
      "         [ 78],\n",
      "         [139],\n",
      "         [166],\n",
      "         [  6],\n",
      "         [102],\n",
      "         [ 69],\n",
      "         [196],\n",
      "         [195],\n",
      "         [  6],\n",
      "         [ 82],\n",
      "         [ 53],\n",
      "         [ 24],\n",
      "         [ 38],\n",
      "         [ 90],\n",
      "         [ 59],\n",
      "         [125],\n",
      "         [ 67],\n",
      "         [ 99],\n",
      "         [ 91],\n",
      "         [122],\n",
      "         [ 33],\n",
      "         [ 53],\n",
      "         [ 70],\n",
      "         [119],\n",
      "         [ 31],\n",
      "         [  8],\n",
      "         [121],\n",
      "         [124],\n",
      "         [136],\n",
      "         [ 89],\n",
      "         [117],\n",
      "         [108],\n",
      "         [ 33],\n",
      "         [ 49],\n",
      "         [  5],\n",
      "         [104],\n",
      "         [  4],\n",
      "         [ 49],\n",
      "         [ 21],\n",
      "         [187],\n",
      "         [157],\n",
      "         [  6],\n",
      "         [ 21],\n",
      "         [128],\n",
      "         [ 78],\n",
      "         [  4],\n",
      "         [ 95],\n",
      "         [ 11],\n",
      "         [196],\n",
      "         [ 46],\n",
      "         [ 96],\n",
      "         [157],\n",
      "         [ 49],\n",
      "         [ 19],\n",
      "         [ 73],\n",
      "         [178],\n",
      "         [ 80],\n",
      "         [ 74],\n",
      "         [ 66],\n",
      "         [  1],\n",
      "         [ 39],\n",
      "         [178],\n",
      "         [123],\n",
      "         [167],\n",
      "         [ 56],\n",
      "         [106],\n",
      "         [  4],\n",
      "         [ 54],\n",
      "         [ 54],\n",
      "         [108],\n",
      "         [ 54],\n",
      "         [129],\n",
      "         [ 27],\n",
      "         [102],\n",
      "         [154],\n",
      "         [187],\n",
      "         [ 15],\n",
      "         [ 12],\n",
      "         [ 95],\n",
      "         [136],\n",
      "         [143],\n",
      "         [ 76],\n",
      "         [171],\n",
      "         [190],\n",
      "         [  8],\n",
      "         [ 30],\n",
      "         [ 31],\n",
      "         [129],\n",
      "         [194],\n",
      "         [ 63],\n",
      "         [153],\n",
      "         [ 45],\n",
      "         [ 17],\n",
      "         [ 82],\n",
      "         [ 85],\n",
      "         [ 23],\n",
      "         [ 62],\n",
      "         [ 39],\n",
      "         [133],\n",
      "         [ 81],\n",
      "         [ 63],\n",
      "         [ 43],\n",
      "         [  3],\n",
      "         [196],\n",
      "         [104],\n",
      "         [ 33],\n",
      "         [184],\n",
      "         [ 28],\n",
      "         [ 53],\n",
      "         [ 77],\n",
      "         [ 32],\n",
      "         [124],\n",
      "         [137],\n",
      "         [133],\n",
      "         [130],\n",
      "         [186],\n",
      "         [ 52],\n",
      "         [128],\n",
      "         [ 51],\n",
      "         [185],\n",
      "         [113],\n",
      "         [188],\n",
      "         [ 80],\n",
      "         [184],\n",
      "         [ 85],\n",
      "         [ 44],\n",
      "         [ 86],\n",
      "         [188],\n",
      "         [ 69],\n",
      "         [ 15],\n",
      "         [146],\n",
      "         [ 92],\n",
      "         [ 50],\n",
      "         [170],\n",
      "         [110],\n",
      "         [ 17],\n",
      "         [ 80],\n",
      "         [ 73],\n",
      "         [ 54],\n",
      "         [ 33],\n",
      "         [190],\n",
      "         [  1],\n",
      "         [197],\n",
      "         [131],\n",
      "         [151],\n",
      "         [ 10],\n",
      "         [124],\n",
      "         [ 72],\n",
      "         [154],\n",
      "         [ 84],\n",
      "         [ 67],\n",
      "         [ 42],\n",
      "         [151],\n",
      "         [ 66],\n",
      "         [188],\n",
      "         [178],\n",
      "         [ 87],\n",
      "         [178],\n",
      "         [113],\n",
      "         [  6],\n",
      "         [ 12],\n",
      "         [140],\n",
      "         [178],\n",
      "         [ 77],\n",
      "         [ 89],\n",
      "         [ 29],\n",
      "         [ 54],\n",
      "         [ 78],\n",
      "         [143],\n",
      "         [119],\n",
      "         [ 97],\n",
      "         [191],\n",
      "         [ 71],\n",
      "         [ 65],\n",
      "         [186],\n",
      "         [135],\n",
      "         [125],\n",
      "         [ 10],\n",
      "         [ 40],\n",
      "         [ 74],\n",
      "         [134],\n",
      "         [103],\n",
      "         [ 57],\n",
      "         [128],\n",
      "         [154],\n",
      "         [157],\n",
      "         [ 61],\n",
      "         [ 78],\n",
      "         [ 84],\n",
      "         [ 63],\n",
      "         [ 32],\n",
      "         [ 49],\n",
      "         [171],\n",
      "         [ 64],\n",
      "         [ 37],\n",
      "         [ 15],\n",
      "         [128],\n",
      "         [ 83],\n",
      "         [165],\n",
      "         [190],\n",
      "         [ 18],\n",
      "         [ 80],\n",
      "         [121],\n",
      "         [152],\n",
      "         [107],\n",
      "         [ 78],\n",
      "         [175],\n",
      "         [128],\n",
      "         [ 53],\n",
      "         [ 80],\n",
      "         [189],\n",
      "         [111],\n",
      "         [ 84],\n",
      "         [166],\n",
      "         [ 17],\n",
      "         [ 53],\n",
      "         [ 36],\n",
      "         [  4],\n",
      "         [121],\n",
      "         [ 16],\n",
      "         [ 90],\n",
      "         [167],\n",
      "         [137],\n",
      "         [ 41],\n",
      "         [ 32],\n",
      "         [198],\n",
      "         [154],\n",
      "         [ 62],\n",
      "         [ 15],\n",
      "         [166],\n",
      "         [168],\n",
      "         [186],\n",
      "         [ 83],\n",
      "         [ 15],\n",
      "         [  6],\n",
      "         [ 78],\n",
      "         [ 45],\n",
      "         [104],\n",
      "         [147],\n",
      "         [ 70],\n",
      "         [125],\n",
      "         [ 33],\n",
      "         [154],\n",
      "         [ 77],\n",
      "         [173],\n",
      "         [133],\n",
      "         [ 99],\n",
      "         [180],\n",
      "         [ 57],\n",
      "         [ 83],\n",
      "         [ 84],\n",
      "         [ 68],\n",
      "         [101],\n",
      "         [ 99]]], dtype=torch.int32), 'r2p_ds_nei_idx2': tensor([[[1180, 1100, 1099,  ...,  940,  939, 1022],\n",
      "         [4204, 4284, 4203,  ..., 4125, 4286, 4206],\n",
      "         [1623, 1624, 1625,  ..., 1706, 1547, 1467],\n",
      "         ...,\n",
      "         [1202, 1203, 1122,  ..., 1363,  962,  963],\n",
      "         [2277, 2197, 2276,  ..., 2356, 2274, 2117],\n",
      "         [4760, 4759, 4680,  ..., 4757, 4682, 4677]]], dtype=torch.int32), 'p2r_ds_nei_idx2': tensor([[[ 37],\n",
      "         [ 37],\n",
      "         [131],\n",
      "         ...,\n",
      "         [ 37],\n",
      "         [144],\n",
      "         [144]]], dtype=torch.int32), 'cld_xyz3': tensor([[[ 3.1206e-01, -2.7075e-01,  1.1850e+00],\n",
      "         [ 6.9067e-02,  4.7119e-01,  1.5360e+00],\n",
      "         [-2.5582e-01, -1.5844e-01,  1.0440e+00],\n",
      "         [ 5.1604e-01, -1.7980e-01,  1.2270e+00],\n",
      "         [-4.5888e-01, -6.1451e-01,  1.6390e+00],\n",
      "         [ 2.5860e-01,  1.9842e-01,  7.1600e-01],\n",
      "         [-6.9783e-02, -8.1997e-02,  1.0440e+00],\n",
      "         [-5.7490e-01,  3.2289e-01,  1.7480e+00],\n",
      "         [-2.3636e-01,  1.0323e-01,  7.9000e-01],\n",
      "         [-1.3659e-01,  2.8042e-02,  8.9600e-01],\n",
      "         [ 1.4110e-01,  4.8989e-01,  1.5030e+00],\n",
      "         [ 9.4864e-02, -3.4675e-02,  9.9200e-01],\n",
      "         [ 2.0843e-01, -3.3942e-02,  1.0220e+00],\n",
      "         [-7.3680e-02, -4.6215e-01,  1.2680e+00],\n",
      "         [ 3.2529e-01, -2.8232e-01,  1.1730e+00],\n",
      "         [ 4.2605e-01, -2.6865e-01,  1.1410e+00],\n",
      "         [ 3.3970e-01, -4.3688e-01,  1.0940e+00],\n",
      "         [-1.7623e-01,  2.9557e-01,  7.5700e-01],\n",
      "         [-6.3222e-01,  3.5227e-01,  1.7130e+00],\n",
      "         [ 2.2092e-01, -2.2963e-01,  1.2190e+00],\n",
      "         [ 3.2443e-01,  7.6898e-02,  8.4900e-01],\n",
      "         [ 3.5964e-02,  4.3093e-01,  1.6160e+00],\n",
      "         [-1.5659e-01,  1.9987e-01,  9.0300e-01],\n",
      "         [ 2.6474e-01,  1.8269e-01,  7.3300e-01],\n",
      "         [ 3.7054e-01, -3.8203e-01,  1.1120e+00],\n",
      "         [ 3.0958e-01,  1.1627e-01,  7.8500e-01],\n",
      "         [ 1.9540e-01, -3.1499e-02,  1.0010e+00],\n",
      "         [-1.4604e-01, -5.2599e-02,  1.0040e+00],\n",
      "         [ 1.1476e-03,  3.4023e-02,  8.8900e-01],\n",
      "         [ 3.4447e-01,  1.5797e-01,  7.3100e-01],\n",
      "         [ 3.5743e-01,  1.5606e-01,  7.3400e-01],\n",
      "         [ 2.6800e-01, -7.6108e-02,  1.0900e+00],\n",
      "         [-5.5589e-01, -5.7098e-01,  1.3700e+00],\n",
      "         [ 4.2678e-01, -3.7723e-01,  1.0870e+00],\n",
      "         [ 5.2055e-01,  5.3034e-01,  1.4770e+00],\n",
      "         [ 2.6384e-01,  5.2527e-01,  1.4700e+00],\n",
      "         [ 2.7807e-01, -4.3475e-01,  1.1230e+00],\n",
      "         [ 3.3758e-01,  2.4888e-01,  6.4900e-01],\n",
      "         [ 2.7371e-01, -7.4208e-02,  1.0900e+00],\n",
      "         [-1.7810e-01, -2.6210e-01,  1.1050e+00],\n",
      "         [-3.7114e-01,  3.6651e-01,  1.6960e+00],\n",
      "         [-7.8315e-01,  4.8989e-01,  1.5030e+00],\n",
      "         [-3.4529e-01, -1.4006e-01,  1.1150e+00],\n",
      "         [-6.4262e-01,  3.8939e-01,  1.6550e+00],\n",
      "         [ 4.1269e-01, -2.5305e-01,  1.3070e+00],\n",
      "         [ 1.0238e-01, -3.7219e-01,  1.4040e+00],\n",
      "         [ 5.2731e-01, -2.3616e-01,  1.1190e+00],\n",
      "         [ 5.7653e-01, -2.1739e-01,  1.2100e+00],\n",
      "         [ 1.3671e-01, -7.3106e-02,  1.0470e+00],\n",
      "         [ 2.4011e-02,  2.8781e-01,  1.7760e+00],\n",
      "         [-4.3758e-01, -2.6578e-02,  1.0130e+00],\n",
      "         [-2.4516e-01, -5.0242e-01,  1.3590e+00],\n",
      "         [ 2.9656e-01,  2.2905e-01,  6.8800e-01],\n",
      "         [-1.8607e-02, -8.1526e-02,  1.0380e+00],\n",
      "         [ 3.6662e-01, -2.3319e-02,  1.0250e+00],\n",
      "         [ 2.6365e-01,  1.1057e-01,  8.3500e-01],\n",
      "         [-3.1307e-03,  5.5235e-01,  1.4210e+00],\n",
      "         [-4.5471e-01, -2.7900e-01,  1.3330e+00],\n",
      "         [ 3.6428e-01, -3.0733e-01,  1.4210e+00],\n",
      "         [ 1.5574e-01,  1.2344e-01,  8.0500e-01],\n",
      "         [ 2.4119e-01, -4.0013e-01,  1.1530e+00],\n",
      "         [ 4.8113e-01, -3.2816e-01,  1.0940e+00],\n",
      "         [-2.0804e-01,  2.0864e-01,  8.4900e-01],\n",
      "         [-4.4882e-02, -4.4667e-01,  1.2680e+00],\n",
      "         [-2.8504e-01,  2.5699e-01,  7.7600e-01],\n",
      "         [ 3.2908e-01, -9.7991e-02,  1.1230e+00],\n",
      "         [-6.6661e-01,  4.9571e-01,  1.4890e+00],\n",
      "         [-7.9711e-02,  1.0880e-01,  8.1100e-01],\n",
      "         [-5.3419e-01, -1.2691e-01,  1.1190e+00],\n",
      "         [ 8.6908e-02,  3.3183e-01,  1.7310e+00],\n",
      "         [ 3.9362e-01, -2.7645e-01,  1.1570e+00],\n",
      "         [ 3.0807e-01, -1.6254e-01,  1.2100e+00],\n",
      "         [-3.4795e-01, -5.4661e-01,  1.5290e+00],\n",
      "         [-5.7637e-01, -2.1483e-01,  1.1730e+00],\n",
      "         [ 1.5860e-01, -4.2629e-01,  1.3810e+00],\n",
      "         [ 5.9945e-02,  4.9711e-01,  1.5090e+00],\n",
      "         [-5.9508e-01, -2.7559e-01,  1.1050e+00],\n",
      "         [-4.2695e-01, -4.2556e-01,  1.4270e+00],\n",
      "         [ 3.6035e-01,  3.4445e-02,  9.4300e-01],\n",
      "         [ 9.4206e-02, -4.1512e-01,  1.3920e+00],\n",
      "         [ 3.3834e-02, -1.7156e-01,  1.1570e+00],\n",
      "         [-1.4276e-01,  2.8695e-01,  8.0700e-01],\n",
      "         [ 4.2458e-01,  6.8127e-03,  9.8900e-01],\n",
      "         [ 3.2294e-01,  1.7568e-01,  7.2000e-01],\n",
      "         [-4.4963e-01, -1.0881e-01,  1.0940e+00],\n",
      "         [ 8.1889e-02, -1.8786e-01,  1.2100e+00],\n",
      "         [-4.8721e-01, -4.5845e-01,  1.4210e+00],\n",
      "         [ 4.9400e-02,  4.9711e-01,  1.5090e+00],\n",
      "         [-2.9265e-01,  2.6500e-01,  7.6400e-01],\n",
      "         [-3.5004e-01, -1.0829e-01,  1.0700e+00],\n",
      "         [-2.5769e-01,  2.6196e-01,  7.4400e-01],\n",
      "         [ 2.9067e-01,  1.0885e-01,  8.3300e-01],\n",
      "         [-3.9240e-01, -2.1688e-01,  1.2190e+00],\n",
      "         [ 3.5160e-01, -2.0230e-01,  1.1260e+00],\n",
      "         [ 4.1333e-01,  4.8504e-01,  1.5290e+00],\n",
      "         [ 1.1425e-01,  1.4291e-01,  7.8100e-01],\n",
      "         [-1.5671e-01,  2.3754e-01,  8.2100e-01],\n",
      "         [-1.3600e-01,  3.5293e-02,  8.8200e-01],\n",
      "         [ 1.2127e-01,  7.8918e-02,  8.3900e-01],\n",
      "         [-4.4566e-01, -5.0249e-01,  1.3920e+00],\n",
      "         [-5.7501e-02,  5.5249e-01,  1.4150e+00],\n",
      "         [ 1.3708e-01, -2.9629e-01,  1.3590e+00],\n",
      "         [-4.4320e-02,  4.9808e-02,  8.6700e-01],\n",
      "         [ 1.6473e-01, -3.2532e-01,  1.3920e+00],\n",
      "         [ 5.8289e-01, -1.4410e-01,  1.1970e+00],\n",
      "         [-8.9994e-01,  3.7497e-01,  1.6550e+00],\n",
      "         [ 4.0294e-01, -1.1228e-01,  1.1490e+00],\n",
      "         [-4.0165e-01, -2.3378e-01,  1.2410e+00],\n",
      "         [ 5.3063e-01, -3.5778e-01,  1.0630e+00],\n",
      "         [-5.8090e-01, -2.8773e-01,  1.1300e+00],\n",
      "         [ 5.7077e-01, -2.8325e-01,  1.0900e+00],\n",
      "         [ 8.4155e-02,  6.6537e-02,  8.4900e-01],\n",
      "         [ 2.9037e-01, -3.0278e-01,  1.1810e+00],\n",
      "         [ 5.3519e-02, -1.7491e-02,  9.0800e-01],\n",
      "         [-4.6871e-01, -4.1872e-01,  1.4640e+00],\n",
      "         [-6.5256e-01,  2.9238e-01,  1.7850e+00],\n",
      "         [-4.5672e-02, -1.6802e-02,  9.5900e-01],\n",
      "         [-1.0362e-01,  9.5765e-03,  9.2300e-01],\n",
      "         [ 3.6761e-01,  2.2001e-01,  6.8600e-01],\n",
      "         [-4.2836e-01,  3.0887e-01,  1.6880e+00],\n",
      "         [-4.5205e-01, -2.0664e-01,  1.0770e+00],\n",
      "         [ 2.1482e-01,  4.8048e-01,  1.5230e+00],\n",
      "         [ 7.4957e-02, -6.4804e-03,  9.1800e-01],\n",
      "         [ 6.8300e-03,  1.1644e-01,  8.2500e-01],\n",
      "         [ 5.7772e-01,  5.6712e-01,  1.4270e+00],\n",
      "         [-3.7256e-01,  8.2943e-02,  8.0700e-01],\n",
      "         [-6.2422e-01, -5.0398e-02,  1.2020e+00],\n",
      "         [ 1.5505e-01, -2.9397e-02,  9.8900e-01],\n",
      "         [-3.1305e-01,  7.2930e-02,  8.2100e-01],\n",
      "         [ 2.4550e-01,  3.9992e-01,  1.6390e+00],\n",
      "         [-6.4619e-01, -8.7253e-03,  1.2360e+00],\n",
      "         [-9.0989e-01, -7.4638e-01,  1.7760e+00],\n",
      "         [ 2.3951e-01, -4.1931e-01,  1.1450e+00],\n",
      "         [-5.6481e-01,  4.6505e-01,  1.5160e+00],\n",
      "         [-8.0224e-01,  5.4415e-01,  1.4520e+00],\n",
      "         [-8.2742e-01,  3.5469e-01,  1.6960e+00],\n",
      "         [ 1.1123e-01, -4.2725e-01,  1.3920e+00],\n",
      "         [-2.2443e-01,  2.7214e-01,  7.3300e-01],\n",
      "         [ 2.9466e-01,  5.3296e-01,  1.4700e+00],\n",
      "         [ 3.1111e-01,  2.2381e-01,  6.8300e-01],\n",
      "         [ 3.2132e-01, -1.4072e-01,  1.0900e+00],\n",
      "         [-6.1350e-01,  3.9992e-01,  1.6390e+00],\n",
      "         [-1.5527e-01, -4.7681e-01,  1.3020e+00],\n",
      "         [-6.3368e-01,  2.5506e-01,  1.4210e+00],\n",
      "         [ 3.4398e-01,  2.6380e-01,  6.4400e-01],\n",
      "         [ 1.7485e-01, -4.2234e-01,  1.3760e+00],\n",
      "         [ 5.2657e-01, -9.6632e-02,  1.1300e+00],\n",
      "         [-8.7108e-01, -7.4644e-01,  1.8940e+00],\n",
      "         [-6.5371e-01,  2.6682e-01,  1.8230e+00],\n",
      "         [ 4.0826e-01,  5.8249e-01,  1.4100e+00],\n",
      "         [-9.2760e-01,  2.6365e-01,  1.8230e+00],\n",
      "         [ 3.9634e-01, -1.2603e-01,  1.1650e+00],\n",
      "         [ 3.7031e-01,  4.3187e-01,  1.6090e+00],\n",
      "         [ 4.7217e-01, -3.9375e-02,  8.6700e-01],\n",
      "         [-1.6010e-01, -2.5240e-02,  9.6200e-01],\n",
      "         [-5.5561e-02, -4.5667e-01,  1.2590e+00],\n",
      "         [ 2.7389e-01, -4.1973e-01,  1.1300e+00],\n",
      "         [-1.9930e-01, -4.5267e-01,  1.3380e+00],\n",
      "         [-4.4453e-01, -2.1227e-01,  1.0770e+00],\n",
      "         [ 3.0064e-01, -1.7156e-01,  1.1050e+00],\n",
      "         [ 3.3351e-01,  2.2401e-01,  6.8000e-01],\n",
      "         [-8.5050e-01,  4.0839e-01,  1.6160e+00],\n",
      "         [-4.5123e-01, -3.0991e-01,  1.0040e+00],\n",
      "         [-6.4416e-01,  2.7636e-01,  1.8230e+00],\n",
      "         [ 5.2525e-01,  5.3250e-01,  1.4830e+00],\n",
      "         [ 4.8455e-01, -2.3665e-01,  1.2680e+00],\n",
      "         [ 4.5236e-02,  2.8199e-02,  9.0100e-01],\n",
      "         [-2.6778e-01,  2.6941e-01,  7.3600e-01],\n",
      "         [ 4.6670e-01,  5.1348e-01,  1.5030e+00],\n",
      "         [-7.8575e-01,  5.2389e-01,  1.4450e+00],\n",
      "         [ 1.4562e-01, -2.2781e-01,  1.2680e+00],\n",
      "         [ 3.3504e-01,  2.1621e-01,  6.9300e-01],\n",
      "         [ 2.0726e-01,  8.4567e-02,  8.3700e-01],\n",
      "         [ 1.8612e-01,  1.8075e-01,  7.5700e-01],\n",
      "         [ 1.4766e-01,  6.7085e-02,  8.5600e-01],\n",
      "         [ 1.4475e-01, -1.0691e-01,  1.0940e+00],\n",
      "         [ 3.2478e-01,  4.5685e-01,  1.5790e+00],\n",
      "         [ 1.1319e-01,  4.9942e-01,  1.5160e+00],\n",
      "         [-2.5438e-01,  3.6478e-01,  1.6880e+00],\n",
      "         [-8.4337e-01,  4.0475e-01,  1.6240e+00],\n",
      "         [-8.6446e-01, -7.4644e-01,  1.8940e+00],\n",
      "         [-9.1941e-01,  3.5427e-01,  1.6800e+00],\n",
      "         [-5.9504e-02, -5.3377e-01,  1.2970e+00],\n",
      "         [-6.9346e-01,  2.8760e-01,  1.7940e+00],\n",
      "         [ 1.3334e-01,  1.0898e-01,  8.2300e-01],\n",
      "         [-7.2305e-01,  5.5483e-01,  1.4210e+00],\n",
      "         [-4.1911e-02,  4.4934e-01,  1.5720e+00],\n",
      "         [ 2.4006e-01,  1.9919e-02,  9.5600e-01],\n",
      "         [-4.5713e-01, -2.1509e-01,  1.0540e+00],\n",
      "         [ 1.8654e-01, -1.5351e-02,  9.7300e-01],\n",
      "         [ 1.8844e-01, -3.4798e-01,  1.2020e+00],\n",
      "         [-6.3319e-01,  4.2345e-01,  1.6090e+00],\n",
      "         [-5.0287e-01,  2.9238e-01,  1.7850e+00],\n",
      "         [ 3.2483e-01,  1.3215e-01,  7.6600e-01],\n",
      "         [ 3.6761e-01,  1.9130e-01,  6.8600e-01],\n",
      "         [ 3.3287e-01,  8.9972e-02,  8.3300e-01],\n",
      "         [-1.1131e-01,  2.8714e-01,  8.5800e-01],\n",
      "         [-6.0281e-01, -2.4288e-01,  1.1230e+00],\n",
      "         [-5.2179e-02, -3.6221e-02,  9.8700e-01],\n",
      "         [-2.0421e-02,  5.6236e-01,  1.4150e+00]]]), 'cld_nei_idx3': tensor([[[  0,  14, 112,  ..., 140, 156, 151],\n",
      "         [  1,  75,  87,  ...,  69, 138, 176],\n",
      "         [  2,  89,  42,  ..., 198,  53, 162],\n",
      "         ...,\n",
      "         [197,  76, 109,  ...,  57, 130,  42],\n",
      "         [198, 116,   6,  ..., 102,  97,  48],\n",
      "         [199,  56, 100,  ..., 129, 176,  69]]], dtype=torch.int32), 'cld_sub_idx3': tensor([[[  0,  14, 112,  70,  93,  19,  71,  15, 159,  24, 190,  60,  44, 140,\n",
      "          156, 151],\n",
      "         [  1,  75,  87, 177,  10,  21, 186, 121,  56, 199, 100,  35, 129,  69,\n",
      "          138, 176],\n",
      "         [  2,  89,  42,  39,  27, 154, 158,   6, 120,  84, 188,  50,  92, 198,\n",
      "           53, 162],\n",
      "         [  3,  47, 165, 104,  46, 146, 151,  44,  15, 106,  70, 110,  93,  61,\n",
      "           71,  14],\n",
      "         [  4,  72, 114,  86,  99,  77,  32,  51, 157,  57, 142, 131, 180, 147,\n",
      "          182, 107],\n",
      "         [  5,  23,  52, 139,  83, 171, 173, 160,  29, 193,  30, 194, 118,  37,\n",
      "           25, 144],\n",
      "         [  6,  53, 198,  27, 116, 154, 117,  80,  11, 113,   9,   2,  28, 122,\n",
      "           48,  97],\n",
      "         [  7,  18, 192, 115, 163, 148, 183,  43, 141, 119, 191,  40, 135, 133,\n",
      "          179, 161],\n",
      "         [  8, 128,  62, 125,  97,  67,  96,  64,   9,  90,  22,  88, 167, 137,\n",
      "           17,  81],\n",
      "         [  9,  97, 117, 154, 102, 116,  67,  27,  28, 198,   8,  22, 166, 123,\n",
      "          113,   6],\n",
      "         [ 10, 177, 121,   1,  75,  87,  35, 138,  21,  56, 129, 199, 186, 176,\n",
      "          100, 152],\n",
      "         [ 11, 127,  48, 122, 113, 189,  26,  12, 166,  53, 175, 116, 198,  28,\n",
      "          187, 111],\n",
      "         [ 12,  26, 189, 127,  48, 187,  31,  38,  11, 175,  54, 140,  65, 122,\n",
      "           78, 159],\n",
      "         [ 13, 155,  63, 182, 142, 157,  51,  79, 136,  45,  74, 145,  39, 101,\n",
      "          190, 103],\n",
      "         [ 14,   0, 112,  70,  93,  15,  24,  19,  71, 159,  60, 156, 190,  44,\n",
      "           33, 132],\n",
      "         [ 15,  70,  61,  93,  14,  46,  33,   0,  24, 165, 112, 151,   3, 110,\n",
      "          108, 106],\n",
      "         [ 16,  24,  36, 156,  33, 132,  60, 112,  14,  61,  70,   0,  15, 190,\n",
      "          108,  93],\n",
      "         [ 17, 137,  81,  96,  90, 167,  64, 196,  88,  62,  22,   8,  67, 123,\n",
      "          128,  97],\n",
      "         [ 18,  43,   7, 141, 115, 183, 191, 163, 148, 192, 135, 119, 179, 133,\n",
      "          161,  40],\n",
      "         [ 19, 170,   0, 112,  71, 190,  14,  85, 159,  93, 101,  60, 140,  70,\n",
      "          175,  65],\n",
      "         [ 20, 195,  91,  55,  25, 193,  78, 172,  30,  29, 187,  83,  23, 174,\n",
      "           59,  82],\n",
      "         [ 21, 186,   1,  87,  75, 177,  69,  10, 121, 129,  49,  56, 199, 100,\n",
      "           35, 176],\n",
      "         [ 22,  62,  96, 196,  81,  67,  97,   8,   9,  17,  64, 102, 137,  90,\n",
      "          117, 123],\n",
      "         [ 23,   5,  83,  52, 139, 173,  29, 193, 171,  25, 160,  30, 194, 118,\n",
      "           55,  91],\n",
      "         [ 24,  33,  16, 156,  36,  70,  61,  14,  15, 112,  60, 132,   0, 108,\n",
      "           93, 190],\n",
      "         [ 25, 193,  91, 195,  55,  20,  29,  30,  83,  23,   5, 172, 194, 171,\n",
      "          173, 139],\n",
      "         [ 26,  12, 189, 127, 187,  48,  11,  31,  38, 175, 122, 113,  54, 174,\n",
      "           78, 140],\n",
      "         [ 27, 154,   6, 198, 117, 116,  53,   9,  97,   2, 102,  28,  89, 113,\n",
      "          166,  39],\n",
      "         [ 28, 166, 102, 113, 122, 111, 116, 123, 117, 198,  67,  97,  98,   9,\n",
      "          174,  11],\n",
      "         [ 29,  30,  83, 193, 194, 171,  25, 118,  23, 160, 139,  52,   5,  37,\n",
      "          195,  91],\n",
      "         [ 30,  29,  83, 193, 194, 171,  25, 118, 160,  23, 139,  52,   5, 195,\n",
      "           37,  91],\n",
      "         [ 31,  38,  65, 140,  12, 159,  26, 175,  54,  48, 106,  71, 189,  93,\n",
      "          151, 127],\n",
      "         [ 32,  99,  86, 114,  77,  72,   4,  57,  51, 109, 157, 107,  76,  73,\n",
      "          197, 142],\n",
      "         [ 33,  24,  61,  16, 108,  15,  70,  14,  36, 156, 110,  46, 112,   0,\n",
      "           93,  60],\n",
      "         [ 34, 164, 168, 124,  94, 149, 152, 138, 176,  35, 121, 129,  10, 177,\n",
      "            1,  75],\n",
      "         [ 35, 138, 121,  10, 176, 177,  94, 149, 152, 168,  75, 129,   1,  87,\n",
      "           34, 164],\n",
      "         [ 36, 156, 132,  60,  16,  24, 112, 190,  33,  14,   0,  70,  15,  61,\n",
      "           19,  93],\n",
      "         [ 37, 144, 160, 139, 171, 118,  52, 194,  83,   5,  29,  30,  23, 193,\n",
      "           25, 173],\n",
      "         [ 38,  31,  65, 140, 159,  12,  54,  26, 175,  48, 106, 151,  71,  93,\n",
      "          189, 127],\n",
      "         [ 39,   2,  42,   6,  89,  27,  80,  92,  53, 107, 158, 155, 154,  13,\n",
      "           63, 120],\n",
      "         [ 40, 119, 178, 192,   7, 141,  18,  43, 191, 133, 115, 163, 148, 183,\n",
      "          186,  66],\n",
      "         [ 41, 169, 134,  66, 185, 161, 179, 191, 133, 105,  43, 141, 135, 181,\n",
      "          143,  18],\n",
      "         [ 42,  89,  84,   2, 158, 120,  92, 188, 107,  50,  68,  39, 162,  27,\n",
      "           73, 154],\n",
      "         [ 43, 141, 191,  18,   7, 115, 133, 183, 135,  66, 163, 179, 148, 161,\n",
      "          192,  41],\n",
      "         [ 44, 165,  58,   3,  70,   0,  14,  15,  71, 112, 151,  47,  93, 106,\n",
      "           19,  46],\n",
      "         [ 45,  79, 136, 103,  74, 145, 101, 170,  63, 190, 155,  13, 182,  19,\n",
      "           85,  58],\n",
      "         [ 46, 110,  47,  61,  15,   3, 104, 108, 146,  70, 165,  33, 151, 106,\n",
      "           93,  14],\n",
      "         [ 47,   3, 104,  46, 165, 110, 146,  15,  61,  44,  70, 151, 108, 106,\n",
      "           93,  33],\n",
      "         [ 48, 175, 127,  11,  26,  12, 189,  31,  38,  53, 122, 187, 113,  80,\n",
      "          159, 166],\n",
      "         [ 49,  69,  21, 186, 129, 178,   1,  87,  75, 177,  10, 121, 176, 152,\n",
      "           40,  56]]], dtype=torch.int32), 'cld_interp_idx3': tensor([[[ 0],\n",
      "         [ 1],\n",
      "         [ 2],\n",
      "         [ 3],\n",
      "         [ 4],\n",
      "         [ 5],\n",
      "         [ 6],\n",
      "         [ 7],\n",
      "         [ 8],\n",
      "         [ 9],\n",
      "         [10],\n",
      "         [11],\n",
      "         [12],\n",
      "         [13],\n",
      "         [14],\n",
      "         [15],\n",
      "         [16],\n",
      "         [17],\n",
      "         [18],\n",
      "         [19],\n",
      "         [20],\n",
      "         [21],\n",
      "         [22],\n",
      "         [23],\n",
      "         [24],\n",
      "         [25],\n",
      "         [26],\n",
      "         [27],\n",
      "         [28],\n",
      "         [29],\n",
      "         [30],\n",
      "         [31],\n",
      "         [32],\n",
      "         [33],\n",
      "         [34],\n",
      "         [35],\n",
      "         [36],\n",
      "         [37],\n",
      "         [38],\n",
      "         [39],\n",
      "         [40],\n",
      "         [41],\n",
      "         [42],\n",
      "         [43],\n",
      "         [44],\n",
      "         [45],\n",
      "         [46],\n",
      "         [47],\n",
      "         [48],\n",
      "         [49],\n",
      "         [42],\n",
      "         [13],\n",
      "         [ 5],\n",
      "         [ 6],\n",
      "         [38],\n",
      "         [25],\n",
      "         [ 1],\n",
      "         [42],\n",
      "         [44],\n",
      "         [23],\n",
      "         [36],\n",
      "         [33],\n",
      "         [22],\n",
      "         [13],\n",
      "         [17],\n",
      "         [38],\n",
      "         [41],\n",
      "         [ 9],\n",
      "         [42],\n",
      "         [49],\n",
      "         [15],\n",
      "         [19],\n",
      "         [ 4],\n",
      "         [42],\n",
      "         [45],\n",
      "         [ 1],\n",
      "         [42],\n",
      "         [32],\n",
      "         [20],\n",
      "         [45],\n",
      "         [ 6],\n",
      "         [17],\n",
      "         [20],\n",
      "         [29],\n",
      "         [42],\n",
      "         [19],\n",
      "         [32],\n",
      "         [ 1],\n",
      "         [17],\n",
      "         [42],\n",
      "         [17],\n",
      "         [20],\n",
      "         [42],\n",
      "         [14],\n",
      "         [34],\n",
      "         [23],\n",
      "         [17],\n",
      "         [ 9],\n",
      "         [28],\n",
      "         [32],\n",
      "         [ 1],\n",
      "         [45],\n",
      "         [28],\n",
      "         [45],\n",
      "         [47],\n",
      "         [41],\n",
      "         [38],\n",
      "         [42],\n",
      "         [33],\n",
      "         [42],\n",
      "         [46],\n",
      "         [28],\n",
      "         [ 0],\n",
      "         [28],\n",
      "         [32],\n",
      "         [ 7],\n",
      "         [28],\n",
      "         [ 9],\n",
      "         [37],\n",
      "         [40],\n",
      "         [42],\n",
      "         [10],\n",
      "         [11],\n",
      "         [28],\n",
      "         [34],\n",
      "         [ 8],\n",
      "         [42],\n",
      "         [26],\n",
      "         [ 8],\n",
      "         [10],\n",
      "         [42],\n",
      "         [ 4],\n",
      "         [36],\n",
      "         [43],\n",
      "         [41],\n",
      "         [43],\n",
      "         [45],\n",
      "         [17],\n",
      "         [35],\n",
      "         [37],\n",
      "         [38],\n",
      "         [43],\n",
      "         [13],\n",
      "         [43],\n",
      "         [37],\n",
      "         [45],\n",
      "         [ 3],\n",
      "         [ 4],\n",
      "         [ 7],\n",
      "         [34],\n",
      "         [18],\n",
      "         [ 3],\n",
      "         [35],\n",
      "         [20],\n",
      "         [27],\n",
      "         [13],\n",
      "         [36],\n",
      "         [13],\n",
      "         [42],\n",
      "         [31],\n",
      "         [37],\n",
      "         [41],\n",
      "         [42],\n",
      "         [ 7],\n",
      "         [34],\n",
      "         [ 3],\n",
      "         [28],\n",
      "         [17],\n",
      "         [34],\n",
      "         [41],\n",
      "         [19],\n",
      "         [37],\n",
      "         [20],\n",
      "         [23],\n",
      "         [28],\n",
      "         [48],\n",
      "         [35],\n",
      "         [10],\n",
      "         [40],\n",
      "         [41],\n",
      "         [ 4],\n",
      "         [41],\n",
      "         [13],\n",
      "         [18],\n",
      "         [28],\n",
      "         [41],\n",
      "         [21],\n",
      "         [26],\n",
      "         [42],\n",
      "         [26],\n",
      "         [19],\n",
      "         [43],\n",
      "         [ 7],\n",
      "         [25],\n",
      "         [30],\n",
      "         [20],\n",
      "         [22],\n",
      "         [42],\n",
      "         [ 6],\n",
      "         [ 1]]], dtype=torch.int32), 'r2p_ds_nei_idx3': tensor([[[1180, 1100, 1099, 1181, 1101, 1098, 1020, 1019, 1021, 1018, 1182,\n",
      "          1102, 1097,  940,  939, 1022],\n",
      "         [4204, 4284, 4203, 4283, 4285, 4205, 4364, 4202, 4123, 4363, 4282,\n",
      "          4365, 4124, 4125, 4286, 4206],\n",
      "         [1623, 1624, 1625, 1703, 1783, 1702, 1704, 1782, 1626, 1784, 1705,\n",
      "          1863, 1785, 1706, 1547, 1467],\n",
      "         [1671, 1670, 1591, 1672, 1592, 1590, 1751, 1511, 1669, 1752, 1512,\n",
      "          1750, 1673, 1593, 1753, 1513],\n",
      "         [ 261,  341,  260,  181,  182,  180,  101,  102,  259,  179,  100,\n",
      "           183,  581,  103,   99,  661],\n",
      "         [4067, 4066, 4147, 3986, 4068, 4146, 4065, 4148, 3987, 3985, 4227,\n",
      "          4228, 4145, 3988, 3906, 4069],\n",
      "         [2036, 2035, 1956, 2037, 1955, 1957, 1875, 1876, 1954, 2038, 2034,\n",
      "          1958, 2115, 2117, 1874, 2116],\n",
      "         [3537, 3457, 3458, 3538, 3536, 3456, 3459, 3378, 3377, 3535, 3617,\n",
      "          3616, 3379, 3539, 3615, 3455],\n",
      "         [3219, 3139, 3220, 3140, 3218, 3138, 3221, 3141, 3059, 3060, 3217,\n",
      "          3137, 3061, 3058, 3222, 3142],\n",
      "         [2590, 2670, 2589, 2669, 2591, 2671, 2668, 2588, 2592, 2510, 2672,\n",
      "          2511, 2509, 2750, 2749, 2667],\n",
      "         [4367, 4368, 4287, 4288, 4447, 4448, 4366, 4286, 4369, 4446, 4289,\n",
      "          4449, 4365, 4207, 4528, 4527],\n",
      "         [2288, 2287, 2207, 2208, 2286, 2289, 2367, 2209, 2368, 2290, 2369,\n",
      "          2210, 2370, 2127, 2128, 2291],\n",
      "         [2295, 2296, 2214, 2297, 2215, 2376, 2216, 2377, 2213, 2294, 2298,\n",
      "          2217, 2378, 2133, 2134, 2293],\n",
      "         [ 357,  437,  358,  438,  517,  518,  356,  359,  439,  276,  597,\n",
      "           275,  519,  598,  436,  355],\n",
      "         [1101, 1100, 1021, 1180, 1020, 1181, 1099, 1102, 1022, 1019, 1182,\n",
      "           941,  940,  942, 1103, 1098],\n",
      "         [1107, 1187, 1108, 1188, 1106, 1027, 1186, 1028, 1109, 1267, 1189,\n",
      "          1268, 1029, 1026, 1266, 1269],\n",
      "         [ 223,  143,  222,  142,  224,  144,  303,  302,  304,  221,  141,\n",
      "           145,  225,  301,  383,  382],\n",
      "         [4664, 4744, 4665, 4663, 4584, 4743, 4745, 4585, 4583, 4504, 4666,\n",
      "          4662, 4505, 4746, 4742, 4503],\n",
      "         [3614, 3615, 3613, 3694, 3535, 3693, 3534, 3616, 3536, 3695, 3533,\n",
      "          3612, 3692, 3774, 3696, 3773],\n",
      "         [1414, 1413, 1493, 1415, 1494, 1495, 1333, 1416, 1573, 1574, 1496,\n",
      "          1335, 1575, 1572, 1254, 1653],\n",
      "         [3028, 3027, 3109, 3108, 3106, 3110, 3107, 3187, 3186, 3105, 3111,\n",
      "          3029, 2947, 3188, 2948, 2946],\n",
      "         [3962, 3963, 4042, 4043, 3961, 4041, 3883, 3882, 3964, 4044, 4122,\n",
      "          3881, 4123, 3884, 3960, 4124],\n",
      "         [3708, 3789, 3707, 3706, 3788, 3870, 3787, 3705, 3869, 3868, 3786,\n",
      "          3950, 3951, 3867, 3785, 3949],\n",
      "         [3906, 3907, 3987, 3986, 3826, 3988, 3905, 3908, 3827, 3825, 3985,\n",
      "          4066, 4067, 3989, 4068, 4065],\n",
      "         [ 544,  545,  465,  464,  624,  543,  625,  466,  546,  385,  463,\n",
      "           384,  623,  626,  386,  383],\n",
      "         [3349, 3348, 3350, 3269, 3268, 3430, 3270, 3429, 3351, 3428, 3431,\n",
      "          3509, 3511, 3271, 3188, 3346],\n",
      "         [2294, 2295, 2214, 2376, 2293, 2213, 2296, 2375, 2374, 2456, 2377,\n",
      "          2212, 2292, 2373, 2297, 2457],\n",
      "         [2110, 2111, 2191, 2190, 2109, 2192, 2112, 2108, 2189, 2030, 2032,\n",
      "          1951, 2270, 2031, 2271, 2028],\n",
      "         [2681, 2680, 2682, 2761, 2600, 2601, 2679, 2760, 2762, 2683, 2599,\n",
      "          2602, 2759, 2763, 2678, 2841],\n",
      "         [3755, 3754, 3674, 3835, 3756, 3675, 3753, 3834, 3836, 3594, 3676,\n",
      "          3672, 3757, 3752, 3833, 3837],\n",
      "         [3675, 3755, 3756, 3676, 3757, 3674, 3754, 3835, 3677, 3594, 3837,\n",
      "          3836, 3758, 3596, 3838, 3834],\n",
      "         [2058, 2059, 2057, 2138, 2139, 2060, 2140, 1978, 2137, 2056, 1979,\n",
      "          1977, 2061, 2141, 1976, 2219],\n",
      "         [  92,   91,  172,  252,  253,  251,  173,  332,  250,  331,  333,\n",
      "           412,  330,  171,  414,  413],\n",
      "         [ 469,  549,  468,  548,  470,  389,  550,  388,  390,  547,  629,\n",
      "           628,  467,  630,  471,  627],\n",
      "         [4546, 4466, 4545, 4547, 4626, 4465, 4627, 4467, 4544, 4625, 4464,\n",
      "          4628, 4548, 4706, 4707, 4705],\n",
      "         [4534, 4533, 4614, 4613, 4453, 4535, 4532, 4454, 4615, 4452, 4612,\n",
      "          4694, 4455, 4695, 4531, 4536],\n",
      "         [ 298,  218,  219,  299,  297,  217,  378,  138,  139,  379,  220,\n",
      "           300,  377,  137,  140,  380],\n",
      "         [4718, 4638, 4637, 4719, 4717, 4639, 4799, 4798, 4636, 4557, 4558,\n",
      "          4556, 4716, 4559, 4555, 4635],\n",
      "         [2059, 2058, 2139, 2138, 2060, 2057, 2140, 1978, 2061, 2137, 2141,\n",
      "          1979, 2056, 1977, 2219, 2220],\n",
      "         [1069, 1070, 1071, 1147,  910,  991, 1150, 1151,  911, 1149, 1146,\n",
      "          1226, 1152,  830, 1145, 1306],\n",
      "         [3625, 3626, 3624, 3703, 3627, 3623, 3546, 3544, 3545, 3543, 3547,\n",
      "          3702, 3628, 3622, 3464, 3463],\n",
      "         [4323, 4244, 4243, 4324, 4322, 4403, 4245, 4402, 4242, 4404, 4325,\n",
      "          4164, 4165, 4246, 4405, 4163],\n",
      "         [1699, 1698, 1778, 1779, 1697, 1777, 1780, 1776, 1696, 1618, 1775,\n",
      "          1858, 1857, 1856, 1695, 1859],\n",
      "         [3773, 3853, 3772, 3774, 3852, 3854, 3694, 3692, 3933, 3775, 3695,\n",
      "          3693, 3855, 3932, 3691, 3614],\n",
      "         [1343, 1344, 1342, 1263, 1264, 1345, 1262, 1341, 1261, 1346, 1340,\n",
      "          1427, 1420, 1339, 1260, 1428],\n",
      "         [ 926, 1006,  925,  927, 1005,  846, 1007,  845,  847, 1086,  924,\n",
      "           928,  766, 1008,  765, 1087],\n",
      "         [1274, 1275, 1355, 1354, 1194, 1195, 1273, 1276, 1196, 1356, 1193,\n",
      "          1115, 1114, 1272, 1352, 1116],\n",
      "         [1435, 1515, 1514, 1516, 1595, 1433, 1513, 1594, 1596, 1593, 1517,\n",
      "          1432, 1675, 1597, 1674, 1512],\n",
      "         [2050, 2049, 2051, 2130, 2131, 2129, 2048, 2052, 2132, 1970, 1969,\n",
      "          2128, 1971, 2047, 2133, 1968],\n",
      "         [3401, 3402, 3482, 3481, 3403, 3483, 3400, 3480, 3561, 3562, 3484,\n",
      "          3563, 3479, 3399, 3560, 3319]]], dtype=torch.int32), 'p2r_ds_nei_idx3': tensor([[[37],\n",
      "         [37],\n",
      "         [ 4],\n",
      "         ...,\n",
      "         [37],\n",
      "         [37],\n",
      "         [37]]], dtype=torch.int32), 'r2p_up_nei_idx0': tensor([[[ 4599,  4439,  4600,  ...,  4119,  4120,  4118],\n",
      "         [16888, 16728, 16887,  ..., 16890, 17046, 17208],\n",
      "         [ 6286,  6287,  6285,  ...,  6131,  6291,  6605],\n",
      "         ...,\n",
      "         [ 4644,  4804,  4805,  ...,  4966,  4486,  4324],\n",
      "         [ 8874,  8873,  8875,  ...,  9036,  8871,  8716],\n",
      "         [18799, 18800, 18959,  ..., 18797, 18957, 19119]]], dtype=torch.int32), 'p2r_up_nei_idx0': tensor([[[ 37],\n",
      "         [ 37],\n",
      "         [ 37],\n",
      "         ...,\n",
      "         [144],\n",
      "         [144],\n",
      "         [144]]], dtype=torch.int32), 'r2p_up_nei_idx1': tensor([[[17838, 18158, 17837,  ..., 17199, 17198, 18161],\n",
      "         [67056, 67055, 67376,  ..., 67694, 67378, 67373],\n",
      "         [24732, 24733, 24734,  ..., 25370, 25056, 25373],\n",
      "         ...,\n",
      "         [31066, 31065, 31067,  ..., 30744, 30427, 31387],\n",
      "         [20356, 20036, 20037,  ..., 20360, 20353, 20033],\n",
      "         [ 5187,  5188,  5186,  ...,  4870,  5510,  5191]]], dtype=torch.int32), 'p2r_up_nei_idx1': tensor([[[ 37],\n",
      "         [ 37],\n",
      "         [ 37],\n",
      "         ...,\n",
      "         [144],\n",
      "         [144],\n",
      "         [ 37]]], dtype=torch.int32), 'r2p_up_nei_idx2': tensor([[[17838, 18158, 17837,  ..., 17199, 17198, 18161],\n",
      "         [67056, 67055, 67376,  ..., 67694, 67378, 67373],\n",
      "         [24732, 24733, 24734,  ..., 25370, 25056, 25373],\n",
      "         ...,\n",
      "         [65422, 65421, 65423,  ..., 66062, 65103, 66061],\n",
      "         [10493, 10812, 10492,  ..., 10495, 10491, 10815],\n",
      "         [43940, 43941, 43621,  ..., 43938, 43623, 44258]]], dtype=torch.int32), 'p2r_up_nei_idx2': tensor([[[1123],\n",
      "         [1123],\n",
      "         [1123],\n",
      "         ...,\n",
      "         [ 144],\n",
      "         [1519],\n",
      "         [1123]]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for b in test_loader:\n",
    "    if count>0:\n",
    "        break\n",
    "    count += 1\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rgb', 'cld_rgb_nrm', 'choose', 'labels', 'rgb_labels', 'dpt_map_m', 'RTs', 'kp_targ_ofst', 'ctr_targ_ofst', 'cls_ids', 'ctr_3ds', 'kp_3ds', 'cld_xyz0', 'cld_nei_idx0', 'cld_sub_idx0', 'cld_interp_idx0', 'r2p_ds_nei_idx0', 'p2r_ds_nei_idx0', 'cld_xyz1', 'cld_nei_idx1', 'cld_sub_idx1', 'cld_interp_idx1', 'r2p_ds_nei_idx1', 'p2r_ds_nei_idx1', 'cld_xyz2', 'cld_nei_idx2', 'cld_sub_idx2', 'cld_interp_idx2', 'r2p_ds_nei_idx2', 'p2r_ds_nei_idx2', 'cld_xyz3', 'cld_nei_idx3', 'cld_sub_idx3', 'cld_interp_idx3', 'r2p_ds_nei_idx3', 'p2r_ds_nei_idx3', 'r2p_up_nei_idx0', 'p2r_up_nei_idx0', 'r2p_up_nei_idx1', 'p2r_up_nei_idx1', 'r2p_up_nei_idx2', 'p2r_up_nei_idx2'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xs2445/envs/ffb6dEnv/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "print(b.keys())\n",
    "for key,val in b.items():\n",
    "    b[key] = torch.tensor(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kps_pth in get_kps: datasets/linemod/kps_orb9_fps/ape_8_kps.txt\n",
      "dict_keys(['rgb', 'cld_rgb_nrm', 'choose', 'labels', 'rgb_labels', 'dpt_map_m', 'RTs', 'kp_targ_ofst', 'ctr_targ_ofst', 'cls_ids', 'ctr_3ds', 'kp_3ds', 'cld_xyz0', 'cld_nei_idx0', 'cld_sub_idx0', 'cld_interp_idx0', 'r2p_ds_nei_idx0', 'p2r_ds_nei_idx0', 'cld_xyz1', 'cld_nei_idx1', 'cld_sub_idx1', 'cld_interp_idx1', 'r2p_ds_nei_idx1', 'p2r_ds_nei_idx1', 'cld_xyz2', 'cld_nei_idx2', 'cld_sub_idx2', 'cld_interp_idx2', 'r2p_ds_nei_idx2', 'p2r_ds_nei_idx2', 'cld_xyz3', 'cld_nei_idx3', 'cld_sub_idx3', 'cld_interp_idx3', 'r2p_ds_nei_idx3', 'p2r_ds_nei_idx3', 'r2p_up_nei_idx0', 'p2r_up_nei_idx0', 'r2p_up_nei_idx1', 'p2r_up_nei_idx1', 'r2p_up_nei_idx2', 'p2r_up_nei_idx2'])\n"
     ]
    }
   ],
   "source": [
    "a = test_ds.__getitem__(0)\n",
    "# for key,val in a.items():\n",
    "#     a[key] = torch.tensor(val).cuda()\n",
    "\n",
    "print(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu102\n"
     ]
    }
   ],
   "source": [
    "# print(config.mini_batch_size)\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#         test_ds, batch_size=config.test_mini_batch_size, shuffle=False,\n",
    "#         num_workers=20\n",
    "#     )\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't redefine method: forward on class: __torch__.models.ffb6d.FFB6D (of Python compilation unit at: 0x5411c90)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e2cba7e34378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# traced_model = torch.jit.trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraced_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# traced_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_prepare_scriptable_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         return torch.jit._recursive.create_script_module(\n\u001b[0;32m-> 1258\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_methods_to_compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m         )\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mAttributeTypeIsSupportedChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconcrete_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcrete_type_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mcreate_methods_and_properties_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# If done before, hooks can overshadow methods that aren't exported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0mproperty_rcbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_callback\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0mconcrete_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_methods_and_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperty_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_hooks_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_hook_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't redefine method: forward on class: __torch__.models.ffb6d.FFB6D (of Python compilation unit at: 0x5411c90)"
     ]
    }
   ],
   "source": [
    "# model.cuda()\n",
    "# traced_model = torch.jit.trace()\n",
    "traced_model = torch.jit.script(model, example_inputs=b)\n",
    "\n",
    "# traced_model\n",
    "# torch.jit.save(traced_model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Byte but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-79af52dfcee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_onnx.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    318\u001b[0m                         \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                         \u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                         custom_opsets, enable_onnx_checker, use_external_data_format)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             custom_opsets=custom_opsets, use_external_data_format=use_external_data_format)\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[1;32m    727\u001b[0m                                 \u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 dynamic_axes=dynamic_axes)\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_jit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mtrace_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_states\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0mwarn_on_static_input_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mONNXTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0m_create_interpreter_name_lookup_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/6895/FFB6D/ffb6d/models/ffb6d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, end_points, scale)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mend_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# ResNet pre + layer1 + layer2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mrgb_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_pre_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rgb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# stride = 2, [bs, c, 240, 320]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;31m# rndla pre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mxyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_break_up_pc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cld_rgb_nrm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ffb6dEnv/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Byte but found Float"
     ]
    }
   ],
   "source": [
    "model.cpu()\n",
    "\n",
    "torch.onnx.export(model, (b, {}), 'model_onnx.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f01a4cfe8fa1d2c878611974700e0b747524615961b95a20a9eafb0a5447127e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('ffb6dEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
